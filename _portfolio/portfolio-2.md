---
title: "Transformers, LLMs, NLP"
excerpt: "Large Language Models (LLMs), such as GPT, BERT, and LLaMA, are built on the Transformer architecture and trained on massive corpora of text. By leveraging billions of parameters and advanced pretraining strategies, LLMs acquire the ability to generate coherent text, answer questions, summarize content, perform reasoning tasks, and adapt to diverse downstream applications with minimal fine-tuning.<br/><br/><img src='/images/transformer.jpg'>"
collection: Research Interests
---

Large Language Models (LLMs) are likely to go much further, but not in a simple “bigger is always better” way. Here’s how their trajectory looks:

## Scaling vs. Efficiency

The first wave of progress came from scaling: larger models with more parameters trained on more data. However, researchers are hitting diminishing returns—marginal accuracy gains cost exponentially more compute and energy. Future LLMs will focus less on raw size and more on efficiency, with techniques like mixture-of-experts, distillation, quantization, and sparsity making models smaller, faster, and more affordable while retaining or even improving performance.

## Reasoning and Agency

Current LLMs are excellent at pattern completion but limited in true reasoning and planning. The next leap involves enhancing logical reasoning, math, and scientific discovery through better architectures, training signals, and integration with external tools. We’ll see LLMs evolve into agents—capable of making decisions, delegating subtasks, and interacting with the world rather than just generating text.

## Domain Specialization

Instead of only general-purpose models, there will be more domain-tuned LLMs: medical, legal, financial, scientific. These will combine a strong general core with retrieval-augmented generation (RAG) and structured knowledge bases, making them more accurate, safer, and trustworthy in specialized applications.

## Multimodal Expansion

LLMs are already extending into vision, speech, and even robotics. Future models will unify all sensory modalities—text, images, audio, video, 3D spatial data—into a single framework, enabling true cross-modal reasoning. For example, diagnosing from both a radiology scan and a written report, or controlling a robot from natural language plus visual input.

## Trust, Alignment, and Regulation

How far LLMs go will also depend on governance. Questions of bias, misinformation, copyright, and data ownership will shape their limits. Efforts in alignment (making AI systems safe, ethical, and aligned with human values) will define whether society embraces or resists the next generation of LLMs.
